#include <iostream>
#include <vector>
#include <random>
#include <cmath>
#include <cassert>
#include <tuple>
#include <string>
#include <type_traits>
#include <cuda_runtime.h>
#include <cublas_v2.h>
#include "tropicalgemm.h"

// è¾…åŠ©å‡½æ•°ï¼šæ£€æŸ¥CUDAé”™è¯¯
#define CHECK_CUDA(call) do { \
    cudaError_t err = call; \
    if (err != cudaSuccess) { \
        std::cerr << "CUDA error in " << __FILE__ << ":" << __LINE__ << " - " << cudaGetErrorString(err) << std::endl; \
        exit(1); \
    } \
} while(0)

#define CHECK_CUBLAS(call) do { \
    cublasStatus_t status = call; \
    if (status != CUBLAS_STATUS_SUCCESS) { \
        std::cerr << "cuBLAS error in " << __FILE__ << ":" << __LINE__ << " - " << status << std::endl; \
        exit(1); \
    } \
} while(0)

// ç”Ÿæˆéšæœºçƒ­å¸¦çŸ©é˜µ
template<typename T>
void generate_tropical_matrix(std::vector<T>& matrix, int rows, int cols, T min_val = -10.0, T max_val = 10.0) {
    std::random_device rd;
    std::mt19937 gen(rd());
    std::uniform_real_distribution<float> dis(min_val, max_val);
    
    matrix.resize(rows * cols);
    for (int i = 0; i < rows * cols; ++i) {
        matrix[i] = static_cast<T>(dis(gen));
    }
}

// CPUå‚è€ƒå®ç°
template<typename T>
void tropical_gemm_cpu_reference(
    bool transA, bool transB,
    int m, int n, int k,
    T alpha, const T* A, int lda,
    const T* B, int ldb,
    T beta, T* C, int ldc) {
    
    for (int i = 0; i < m; ++i) {
        for (int j = 0; j < n; ++j) {
            T sum = static_cast<T>(-INFINITY);
            
            for (int l = 0; l < k; ++l) {
                T a_val, b_val;
                
                if (!transA) {
                    a_val = A[i * lda + l];
                } else {
                    a_val = A[l * lda + i];
                }
                
                if (!transB) {
                    b_val = B[l * ldb + j];
                } else {
                    b_val = B[j * ldb + l];
                }
                
                // çƒ­å¸¦ä»£æ•°è¿ç®—: (a âŠ— b) = a + b, (a âŠ• b) = max(a, b)
                T product = a_val + b_val;
                sum = std::max(sum, product);
            }
            
            // åº”ç”¨alphaå’Œbeta
            T result = alpha + sum;
            if (beta != static_cast<T>(-INFINITY)) {
                T old_val = beta + C[i * ldc + j];
                result = std::max(result, old_val);
            }
            
            C[i * ldc + j] = result;
        }
    }
}

// æ£€æŸ¥ç»“æœæ­£ç¡®æ€§
template<typename T>
bool check_results(const std::vector<T>& gpu_result, const std::vector<T>& cpu_result, 
                  int m, int n, T tolerance = 1e-4) {
    bool passed = true;
    int errors = 0;
    const int max_errors_to_show = 10;
    
    for (int i = 0; i < m; ++i) {
        for (int j = 0; j < n; ++j) {
            int idx = i * n + j;
            T gpu_val = gpu_result[idx];
            T cpu_val = cpu_result[idx];
            T diff = std::abs(gpu_val - cpu_val);
            
            if (diff > tolerance) {
                if (errors < max_errors_to_show) {
                    std::cout << "Mismatch at (" << i << "," << j << "): GPU=" 
                             << gpu_val << ", CPU=" << cpu_val 
                             << ", diff=" << diff << std::endl;
                }
                errors++;
                passed = false;
            }
        }
    }
    
    if (errors > 0) {
        std::cout << "Total errors: " << errors << " out of " << (m * n) << " elements" << std::endl;
    }
    
    return passed;
}

// ç±»å‹ç‰¹åŒ–çš„GPUè°ƒç”¨å‡½æ•°
template<typename T>
cublasStatus_t call_tropical_gemm(cublasHandle_t handle, cublasOperation_t transA, cublasOperation_t transB, 
                                 int m, int n, int k, T alpha, const T *A, int lda, 
                                 const T *B, int ldb, T beta, T *C, int ldc);

// floatç‰¹åŒ–
template<>
cublasStatus_t call_tropical_gemm<float>(cublasHandle_t handle, cublasOperation_t transA, cublasOperation_t transB, 
                                        int m, int n, int k, float alpha, const float *A, int lda, 
                                        const float *B, int ldb, float beta, float *C, int ldc) {
    printf("calling cutmsSgemm...\n");
    return cutmsSgemm(handle, transA, transB, m, n, k, alpha, A, lda, B, ldb, beta, C, ldc);
}

// doubleç‰¹åŒ–
template<>
cublasStatus_t call_tropical_gemm<double>(cublasHandle_t handle, cublasOperation_t transA, cublasOperation_t transB, 
                                         int m, int n, int k, double alpha, const double *A, int lda, 
                                         const double *B, int ldb, double beta, double *C, int ldc) {
    printf("calling cutmsDgemm...\n");
    return cutmsDgemm(handle, transA, transB, m, n, k, alpha, A, lda, B, ldb, beta, C, ldc);
}

// æµ‹è¯•å•ä¸ªé…ç½®
template<typename T>
bool test_configuration(cublasOperation_t transA, cublasOperation_t transB, 
                       int m, int n, int k, const std::string& test_name) {
    
    std::cout << "\nTesting " << test_name << " (" << m << "x" << n << "x" << k << ")..." << std::endl;
    
    // ç”Ÿæˆæµ‹è¯•æ•°æ®
    std::vector<T> h_A, h_B, h_C_gpu, h_C_cpu;
    
    int lda = (transA == CUBLAS_OP_N) ? k : m;
    int ldb = (transB == CUBLAS_OP_N) ? n : k;
    int ldc = n;
    
    generate_tropical_matrix(h_A, (transA == CUBLAS_OP_N) ? m : k, 
                           (transA == CUBLAS_OP_N) ? k : m);
    generate_tropical_matrix(h_B, (transB == CUBLAS_OP_N) ? k : n, 
                           (transB == CUBLAS_OP_N) ? n : k);
    
    h_C_gpu.resize(m * n, static_cast<T>(1.0));
    h_C_cpu.resize(m * n, static_cast<T>(-INFINITY));
    
    T alpha = static_cast<T>(0.0);
    T beta = static_cast<T>(-INFINITY);
    
    // GPUè®¡ç®—
    T *d_A, *d_B, *d_C;
    CHECK_CUDA(cudaMalloc(&d_A, h_A.size() * sizeof(T)));
    CHECK_CUDA(cudaMalloc(&d_B, h_B.size() * sizeof(T)));
    CHECK_CUDA(cudaMalloc(&d_C, h_C_gpu.size() * sizeof(T)));
    
    CHECK_CUDA(cudaMemcpy(d_A, h_A.data(), h_A.size() * sizeof(T), cudaMemcpyHostToDevice));
    CHECK_CUDA(cudaMemcpy(d_B, h_B.data(), h_B.size() * sizeof(T), cudaMemcpyHostToDevice));
    CHECK_CUDA(cudaMemcpy(d_C, h_C_gpu.data(), h_C_gpu.size() * sizeof(T), cudaMemcpyHostToDevice));
    
    // åˆ›å»ºcuBLASå¥æŸ„
    cublasHandle_t handle;
    CHECK_CUBLAS(cublasCreate(&handle));
    
    // è°ƒç”¨GPUå‡½æ•° - ä½¿ç”¨ç‰¹åŒ–å‡½æ•°
    printf("calling GPU function...\n");
    cublasStatus_t status = call_tropical_gemm(handle, transA, transB, m, n, k, alpha, d_A, lda, d_B, ldb, beta, d_C, ldc);
    
    if (status != CUBLAS_STATUS_SUCCESS) {
        std::cerr << "GPU kernel failed with status: " << status << std::endl;
        return false;
    }
    
    CHECK_CUDA(cudaDeviceSynchronize());
    CHECK_CUDA(cudaMemcpy(h_C_gpu.data(), d_C, h_C_gpu.size() * sizeof(T), cudaMemcpyDeviceToHost));
    
    // CPUå‚è€ƒè®¡ç®—
    tropical_gemm_cpu_reference(
        transA == CUBLAS_OP_T, transB == CUBLAS_OP_T,
        m, n, k, alpha, h_A.data(), lda, h_B.data(), ldb, beta, h_C_cpu.data(), ldc
    );
    
    // æ£€æŸ¥ç»“æœ
    bool passed = check_results(h_C_gpu, h_C_cpu, m, n, static_cast<T>(1e-4));
    
    // æ¸…ç†
    CHECK_CUDA(cudaFree(d_A));
    CHECK_CUDA(cudaFree(d_B));
    CHECK_CUDA(cudaFree(d_C));
    CHECK_CUBLAS(cublasDestroy(handle));
    
    std::cout << test_name << ": " << (passed ? "PASSED" : "FAILED") << std::endl;
    return passed;
}

void check_cuda_environment() {
    printf("ğŸ” Checking CUDA environment...\n");
    
    // æ£€æŸ¥CUDAç‰ˆæœ¬
    int runtime_version, driver_version;
    cudaRuntimeGetVersion(&runtime_version);
    cudaDriverGetVersion(&driver_version);
    printf("CUDA Runtime: %d, Driver: %d\n", runtime_version, driver_version);
    
    // æ£€æŸ¥è®¾å¤‡æ•°é‡
    int device_count;
    cudaGetDeviceCount(&device_count);
    printf("Device count: %d\n", device_count);
    
    if (device_count == 0) {
        printf("âŒ No CUDA devices found!\n");
        return;
    }
    
    // æ£€æŸ¥å½“å‰è®¾å¤‡
    int current_device;
    cudaGetDevice(&current_device);
    printf("Current device: %d\n", current_device);
    
    // æ£€æŸ¥è®¾å¤‡å±æ€§
    cudaDeviceProp prop;
    cudaGetDeviceProperties(&prop, current_device);
    printf("Device: %s\n", prop.name);
    printf("Compute capability: %d.%d\n", prop.major, prop.minor);
    printf("Max threads per block: %d\n", prop.maxThreadsPerBlock);
    printf("Shared memory per block: %zu bytes\n", prop.sharedMemPerBlock);
    
    // æµ‹è¯•åŸºæœ¬å†…å­˜åˆ†é…
    float* test_ptr;
    cudaError_t err = cudaMalloc(&test_ptr, 1024);
    if (err != cudaSuccess) {
        printf("âŒ cudaMalloc failed: %s\n", cudaGetErrorString(err));
    } else {
        printf("âœ… Basic cudaMalloc works\n");
        cudaFree(test_ptr);
    }
}

int main() {

    check_cuda_environment();

    std::cout << "=== CuTropicalGEMM Test Suite ===" << std::endl;
    
    // æ£€æŸ¥CUDAè®¾å¤‡
    int deviceCount;
    CHECK_CUDA(cudaGetDeviceCount(&deviceCount));
    if (deviceCount == 0) {
        std::cerr << "No CUDA devices found!" << std::endl;
        return 1;
    }
    
    CHECK_CUDA(cudaSetDevice(2));
    
    cudaDeviceProp prop;
    CHECK_CUDA(cudaGetDeviceProperties(&prop, 0));
    std::cout << "Using device: " << prop.name << std::endl;
    std::cout << "Compute capability: " << prop.major << "." << prop.minor << std::endl;
    
    bool all_passed = true;
    
    // æµ‹è¯•ä¸åŒçš„çŸ©é˜µå¤§å°å’Œè½¬ç½®ç»„åˆ
    std::vector<std::tuple<int, int, int>> test_sizes = {
        std::make_tuple(64, 64, 64),      // å°çŸ©é˜µ
        std::make_tuple(128, 128, 128),   // ä¸­ç­‰çŸ©é˜µ
        std::make_tuple(256, 256, 256),   // å¤§çŸ©é˜µ
        std::make_tuple(512, 256, 128),   // éæ­£æ–¹å½¢çŸ©é˜µ
        std::make_tuple(100, 200, 150)    // é2çš„å¹‚çŸ©é˜µ
    };
    
    std::vector<std::pair<cublasOperation_t, std::string>> operations = {
        std::make_pair(CUBLAS_OP_N, "N"),
        std::make_pair(CUBLAS_OP_T, "T")
    };
    
    // æµ‹è¯•floatç±»å‹
    std::cout << "\n=== Testing Float Precision ===" << std::endl;
    for (const auto& size : test_sizes) {
        int m, n, k;
        std::tie(m, n, k) = size;
        
        for (const auto& opA : operations) {
            for (const auto& opB : operations) {
                std::string test_name = "Float_" + opA.second + opB.second;
                bool passed = test_configuration<float>(opA.first, opB.first, m, n, k, test_name);
                all_passed = all_passed && passed;
            }
        }
    }
    
    // æµ‹è¯•doubleç±»å‹
    std::cout << "\n=== Testing Double Precision ===" << std::endl;
    for (const auto& size : test_sizes) {
        int m, n, k;
        std::tie(m, n, k) = size;
        
        for (const auto& opA : operations) {
            for (const auto& opB : operations) {
                std::string test_name = "Double_" + opA.second + opB.second;
                bool passed = test_configuration<double>(opA.first, opB.first, m, n, k, test_name);
                all_passed = all_passed && passed;
            }
        }
    }
    
    // è¾¹ç•Œæƒ…å†µæµ‹è¯•
    std::cout << "\n=== Testing Edge Cases ===" << std::endl;
    
    // å¾ˆå°çš„çŸ©é˜µ
    all_passed = all_passed && test_configuration<float>(CUBLAS_OP_N, CUBLAS_OP_N, 1, 1, 1, "Float_1x1x1");
    all_passed = all_passed && test_configuration<float>(CUBLAS_OP_N, CUBLAS_OP_N, 2, 2, 2, "Float_2x2x2");
    
    // å¾ˆå¤§çš„Kç»´åº¦
    all_passed = all_passed && test_configuration<float>(CUBLAS_OP_N, CUBLAS_OP_T, 64, 64, 1024, "Float_LargeK");
    
    std::cout << "\n=== Test Summary ===" << std::endl;
    std::cout << "Overall result: " << (all_passed ? "ALL TESTS PASSED" : "SOME TESTS FAILED") << std::endl;
    
    return all_passed ? 0 : 1;
}